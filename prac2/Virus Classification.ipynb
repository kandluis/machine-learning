{
 "metadata": {
  "name": "",
  "signature": "sha256:faa00bc5f890e343583821923638c5e30204334187917dc7a3ef8f4f0dab82dc"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## This file provides starter code for extracting features from the xml files and\n",
      "## for doing some learning.\n",
      "##\n",
      "## The basic set-up: \n",
      "## ----------------\n",
      "## main() will run code to extract features, learn, and make predictions.\n",
      "## \n",
      "## extract_feats() is called by main(), and it will iterate through the \n",
      "## train/test directories and parse each xml file into an xml.etree.ElementTree, \n",
      "## which is a standard python object used to represent an xml file in memory.\n",
      "## (More information about xml.etree.ElementTree objects can be found here:\n",
      "## http://docs.python.org/2/library/xml.etree.elementtree.html\n",
      "## and here: http://eli.thegreenplace.net/2012/03/15/processing-xml-in-python-with-elementtree/)\n",
      "## It will then use a series of \"feature-functions\" that you will write/modify\n",
      "## in order to extract dictionaries of features from each ElementTree object.\n",
      "## Finally, it will produce an N x D sparse design matrix containing the union\n",
      "## of the features contained in the dictionaries produced by your \"feature-functions.\"\n",
      "## This matrix can then be plugged into your learning algorithm.\n",
      "##\n",
      "## The learning and prediction parts of main() are largely left to you, though\n",
      "## it does contain code that randomly picks class-specific weights and predicts\n",
      "## the class with the weights that give the highest score. If your prediction\n",
      "## algorithm involves class-specific weights, you should, of course, learn \n",
      "## these class-specific weights in a more intelligent way.\n",
      "##\n",
      "## Feature-functions:\n",
      "## --------------------\n",
      "## \"feature-functions\" are functions that take an ElementTree object representing\n",
      "## an xml file (which contains, among other things, the sequence of system calls a\n",
      "## piece of potential malware has made), and returns a dictionary mapping feature names to \n",
      "## their respective numeric values. \n",
      "## For instance, a simple feature-function might map a system call history to the\n",
      "## dictionary {'first_call-load_image': 1}. This is a boolean feature indicating\n",
      "## whether the first system call made by the executable was 'load_image'. \n",
      "## Real-valued or count-based features can of course also be defined in this way. \n",
      "## Because this feature-function will be run over ElementTree objects for each \n",
      "## software execution history instance, we will have the (different)\n",
      "## feature values of this feature for each history, and these values will make up \n",
      "## one of the columns in our final design matrix.\n",
      "## Of course, multiple features can be defined within a single dictionary, and in\n",
      "## the end all the dictionaries returned by feature functions (for a particular\n",
      "## training example) will be unioned, so we can collect all the feature values \n",
      "## associated with that particular instance.\n",
      "##\n",
      "## Two example feature-functions, first_last_system_call_feats() and \n",
      "## system_call_count_feats(), are defined below.\n",
      "## The first of these functions indicates what the first and last system-calls \n",
      "## made by an executable are, and the second records the total number of system\n",
      "## calls made by an executable.\n",
      "##\n",
      "## What you need to do:\n",
      "## --------------------\n",
      "## 1. Write new feature-functions (or modify the example feature-functions) to\n",
      "## extract useful features for this prediction task.\n",
      "## 2. Implement an algorithm to learn from the design matrix produced, and to\n",
      "## make predictions on unseen data. Naive code for these two steps is provided\n",
      "## below, and marked by TODOs.\n",
      "##\n",
      "## Computational Caveat\n",
      "## --------------------\n",
      "## Because the biggest of any of the xml files is only around 35MB, the code below \n",
      "## will parse an entire xml file and store it in memory, compute features, and\n",
      "## then get rid of it before parsing the next one. Storing the biggest of the files \n",
      "## in memory should require at most 200MB or so, which should be no problem for\n",
      "## reasonably modern laptops. If this is too much, however, you can lower the\n",
      "## memory requirement by using ElementTree.iterparse(), which does parsing in\n",
      "## a streaming way. See http://eli.thegreenplace.net/2012/03/15/processing-xml-in-python-with-elementtree/\n",
      "## for an example. \n",
      "\n",
      "import os\n",
      "from collections import Counter\n",
      "try:\n",
      "    import xml.etree.cElementTree as ET\n",
      "except ImportError:\n",
      "    import xml.etree.ElementTree as ET\n",
      "import numpy as np\n",
      "\n",
      "# used for data manipulation\n",
      "from scipy import sparse\n",
      "from scipy import stats\n",
      "\n",
      "import json\n",
      "\n",
      "# used to create bag of words feature\n",
      "import sklearn.feature_extraction\n",
      "\n",
      "# used for dataframe manipulation\n",
      "import pandas as pd\n",
      "\n",
      "import util"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def extract_feats_single_file(ffs, direc=\"train\", virus=None):\n",
      "    '''\n",
      "    arguments:\n",
      "        ffs are a list of feature-functions.\n",
      "        direct is a directory containing xml files (expected to be train or test).\n",
      "        \n",
      "    returns:\n",
      "        a dictionary with the features for the single virus file. The file is selected\n",
      "        randomly if virus is None, otherwise the specified virus type is used\n",
      "    '''\n",
      "    for datafile in os.listdir(direc):\n",
      "        # extract id and true class (if available) from filename\n",
      "        id_str,clazz = datafile.split('.')[:2]\n",
      "        if virus is None or virus == clazz:\n",
      "            break\n",
      "            \n",
      "    tree = ET.parse(os.path.join(direc,datafile))\n",
      "    return [ff(tree) for ff in ffs]\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def extract_feats(ffs, direc=\"train\", global_feat_dict=None):\n",
      "    \"\"\"\n",
      "    arguments:\n",
      "      ffs are a list of feature-functions.\n",
      "      direc is a directory containing xml files (expected to be train or test).\n",
      "      global_feat_dict is a dictionary mapping feature_names to column-numbers; it\n",
      "      should only be provided when extracting features from test data, so that \n",
      "      the columns of the test matrix align correctly.\n",
      "\n",
      "    returns: \n",
      "      a sparse design matrix, a dict mapping features to column-numbers,\n",
      "      a vector of target classes, and a list of system-call-history ids in order \n",
      "      of their rows in the design matrix.\n",
      "      \n",
      "      Note: the vector of target classes returned will contain the true indices of the\n",
      "      target classes on the training data, but will contain only -1's on the test\n",
      "      data\n",
      "    \"\"\"\n",
      "    fds = [] # list of feature dicts\n",
      "    classes = []\n",
      "    ids = [] \n",
      "    for datafile in os.listdir(direc):\n",
      "        # extract id and true class (if available) from filename\n",
      "        id_str,clazz = datafile.split('.')[:2]\n",
      "        ids.append(id_str)\n",
      "        # add target class if this is training data\n",
      "        try:\n",
      "            classes.append(util.malware_classes.index(clazz))\n",
      "        except ValueError:\n",
      "            # we should only fail to find the label in our list of malware classes\n",
      "            # if this is test data, which always has an \"X\" label\n",
      "            assert clazz == \"X\"\n",
      "            classes.append(-1)\n",
      "        rowfd = {}\n",
      "        # parse file as an xml document\n",
      "        tree = ET.parse(os.path.join(direc,datafile))\n",
      "        # accumulate features\n",
      "        [rowfd.update(ff(tree)) for ff in ffs]\n",
      "        fds.append(rowfd)\n",
      "        \n",
      "    X,feat_dict = make_design_mat(fds,global_feat_dict)\n",
      "    return X, feat_dict, np.array(classes), ids\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "def make_design_mat(fds, global_feat_dict=None):\n",
      "    \"\"\"\n",
      "    arguments:\n",
      "      fds is a list of feature dicts (one for each row).\n",
      "      global_feat_dict is a dictionary mapping feature_names to column-numbers; it\n",
      "      should only be provided when extracting features from test data, so that \n",
      "      the columns of the test matrix align correctly.\n",
      "       \n",
      "    returns: \n",
      "        a sparse NxD design matrix, where N == len(fds) and D is the number of\n",
      "        the union of features defined in any of the fds \n",
      "    \"\"\"\n",
      "    if global_feat_dict is None:\n",
      "        all_feats = set()\n",
      "        [all_feats.update(fd.keys()) for fd in fds]\n",
      "        feat_dict = dict([(feat, i) for i, feat in enumerate(sorted(all_feats))])\n",
      "    else:\n",
      "        feat_dict = global_feat_dict\n",
      "        \n",
      "    cols = []\n",
      "    rows = []\n",
      "    data = []        \n",
      "    for i in xrange(len(fds)):\n",
      "        temp_cols = []\n",
      "        temp_data = []\n",
      "        for feat,val in fds[i].iteritems():\n",
      "            try:\n",
      "                # update temp_cols iff update temp_data\n",
      "                temp_cols.append(feat_dict[feat])\n",
      "                temp_data.append(val)\n",
      "            except KeyError as ex:\n",
      "                if global_feat_dict is not None:\n",
      "                    pass  # new feature in test data; nbd\n",
      "                else:\n",
      "                    raise ex\n",
      "\n",
      "        # all fd's features in the same row\n",
      "        k = len(temp_cols)\n",
      "        cols.extend(temp_cols)\n",
      "        data.extend(temp_data)\n",
      "        rows.extend([i]*k)\n",
      "\n",
      "    assert len(cols) == len(rows) and len(rows) == len(data)\n",
      "   \n",
      "\n",
      "    X = sparse.csr_matrix((np.array(data),\n",
      "                   (np.array(rows), np.array(cols))),\n",
      "                   shape=(len(fds), len(feat_dict)))\n",
      "    return X, feat_dict\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Here are two example feature-functions. They each take an xml.etree.ElementTree object, \n",
      "# (i.e., the result of parsing an xml file) and returns a dictionary mapping \n",
      "# feature-names to numeric values.\n",
      "def first_last_system_call_feats(tree):\n",
      "    \"\"\"\n",
      "    arguments:\n",
      "      tree is an xml.etree.ElementTree object\n",
      "    returns:\n",
      "      a dictionary mapping 'first_call-x' to 1 if x was the first system call\n",
      "      made, and 'last_call-y' to 1 if y was the last system call made. \n",
      "      (in other words, it returns a dictionary indicating what the first and \n",
      "      last system calls made by an executable were.)\n",
      "    \"\"\"\n",
      "    c = Counter()\n",
      "    in_all_section = False\n",
      "    first = True # is this the first system call\n",
      "    last_call = None # keep track of last call we've seen\n",
      "    for el in tree.iter():\n",
      "        # ignore everything outside the \"all_section\" element\n",
      "        if el.tag == \"all_section\" and not in_all_section:\n",
      "            in_all_section = True\n",
      "        elif el.tag == \"all_section\" and in_all_section:\n",
      "            in_all_section = False\n",
      "        elif in_all_section:\n",
      "            if first:\n",
      "                c[\"first_call-\"+el.tag] = 1\n",
      "                first = False\n",
      "            last_call = el.tag  # update last call seen\n",
      "            \n",
      "    # finally, mark last call seen\n",
      "    c[\"last_call-\"+last_call] = 1\n",
      "    return c"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def system_call_count_feats(tree):\n",
      "    \"\"\"\n",
      "    arguments:\n",
      "      tree is an xml.etree.ElementTree object\n",
      "    returns:\n",
      "      a dictionary mapping 'num_system_calls' to the number of system_calls\n",
      "      made by an executable (summed over all processes)\n",
      "    \"\"\"\n",
      "    c = Counter()\n",
      "    in_all_section = False\n",
      "    for el in tree.iter():\n",
      "        # ignore everything outside the \"all_section\" element\n",
      "        if el.tag == \"all_section\" and not in_all_section:\n",
      "            in_all_section = True\n",
      "        elif el.tag == \"all_section\" and in_all_section:\n",
      "            in_all_section = False\n",
      "        elif in_all_section:\n",
      "            c['num_system_calls'] += 1\n",
      "    return c"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def tag_counts_feats(tree):\n",
      "    \"\"\"\n",
      "    arguments:\n",
      "        tree is an xml.etree.ElementTree object\n",
      "    returns:\n",
      "        a dictionary mapping 'tag' to the number of times 'tag' appears in the .xml file\n",
      "    \"\"\"\n",
      "    c = Counter()\n",
      "    for el in tree.iter():\n",
      "        # count the tags as you see them\n",
      "        try:\n",
      "            c[el.tag] += 1\n",
      "        except KeyError:\n",
      "            c[el.tag] = 1\n",
      "    return c\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "extract_feats_single_file([tag_counts_feats])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "[Counter({'query_value': 242, 'load_dll': 133, 'open_key': 96, 'enum_window': 47, 'destroy_window': 42, 'vm_protect': 36, 'open_file': 15, 'get_system_directory': 14, 'create_window': 8, 'create_mutex': 8, 'get_file_attributes': 7, 'find_file': 6, 'thread': 5, 'all_section': 5, 'enum_keys': 4, 'show_window': 4, 'process': 3, 'sleep': 3, 'load_image': 3, 'open_process': 3, 'check_for_debugger': 2, 'kill_process': 2, 'set_windows_hook': 2, 'find_window': 2, 'create_thread': 2, 'com_create_instance': 2, 'get_windows_directory': 2, 'com_get_class_object': 1, 'create_process': 1, 'create_file': 1, 'set_file_attributes': 1, 'set_file_time': 1, 'enum_values': 1, 'processes': 1})]"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def bag_of_words_feat(tree, frequency=False, count=True):\n",
      "    \"\"\"\n",
      "    arguments: same as always boys\n",
      "    returns:\n",
      "        a dictionary mapping 'word' to the frequency of that word in the file\n",
      "    \"\"\"\n",
      "    # we want to extract words using regular expressions\n",
      "    import re\n",
      "    \n",
      "    root = tree.getroot()\n",
      "    text = ET.tostring(root)\n",
      "    split_text = re.findall(r\"[\\w']+\", text)\n",
      "    cv = sklearn.feature_extraction.text.CountVectorizer(split_text)\n",
      "    cv.fit_transform(split_text)\n",
      "    vocab = cv.vocabulary_ if count else {}\n",
      "    freq_dict = {key + \"_freq\" :(vocab[key]/sum(vocab.values())) for key in vocab.keys()} if frequency else {}\n",
      "    \n",
      "    return dict(vocab.items() + freq_dict.items())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "r = extract_feats_single_file([bag_of_words_feat])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def main(outputfile = \"mypredictions.csv\"):\n",
      "    train_dir = \"train\"\n",
      "    test_dir = \"test\"\n",
      "    \n",
      "    # TODO put the names of the feature functions you've defined above in this list\n",
      "    ffs = [first_last_system_call_feats, system_call_count_feats]\n",
      "    \n",
      "    # extract features\n",
      "    print \"extracting training features...\"\n",
      "    X_train,global_feat_dict,t_train,train_ids = extract_feats(ffs, train_dir)\n",
      "    print \"done extracting training features\"\n",
      "    print\n",
      "    \n",
      "    # TODO train here, and learn your classification parameters\n",
      "    print \"learning...\"\n",
      "    learned_W = np.random.random((len(global_feat_dict),len(util.malware_classes)))\n",
      "    print \"done learning\"\n",
      "    print\n",
      "    \n",
      "    # get rid of training data and load test data\n",
      "    del X_train\n",
      "    del t_train\n",
      "    del train_ids\n",
      "    print \"extracting test features...\"\n",
      "    X_test,_,t_ignore,test_ids = extract_feats(ffs, test_dir, global_feat_dict=global_feat_dict)\n",
      "    print \"done extracting test features\"\n",
      "    print\n",
      "    \n",
      "    # TODO make predictions on text data and write them out\n",
      "    print \"making predictions...\"\n",
      "    preds = np.argmax(X_test.dot(learned_W),axis=1)\n",
      "    print \"done making predictions\"\n",
      "    print\n",
      "    \n",
      "    print \"writing predictions...\"\n",
      "    util.write_predictions(preds, test_ids, outputfile)\n",
      "    print \"done!\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def test_feat_extraction(feature_function, setdir = \"train\"):\n",
      "    '''\n",
      "    arguments:\n",
      "        feature function to run on data for data extraction on the training_set\n",
      "    returns:\n",
      "        extracted features\n",
      "    '''\n",
      "    print \"testing feature extraction\"\n",
      "    X_train, global_feat_dict, t_train, train_ids = extract_feats([feature_function], setdir)\n",
      "    \n",
      "    return X\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def save_and_load(featurefile, train_dir, ffs = None):\n",
      "    # load features from textfile if possible (so we don't waste time recalculating this!)\n",
      "    if ffs is None:\n",
      "        print \"loading features from file: {}\".format(featurefile)\n",
      "        X_train = util.load_sparse_csr(featurefile + \"_mat\")\n",
      "        global_fead_dict = json.load(open(feature_file + \"_dict.save\"))\n",
      "        t_train = np.load(featurefile + \"_t_train\")\n",
      "        train_ids = np.load(featurefile + \"_train_ids\")\n",
      "        print \"loaded features\"\n",
      "    else:\n",
      "        print \"generating feature set and saving to file: {}\".format(featurefile)\n",
      "        X_train, global_feat_dict, t_train, train_ids = extract_feats(ffs, train_dir)\n",
      "        json.dump(global_feat_dict, open(featurefile + \"_dict.save\", \"w\"))\n",
      "        np.save(featurefile + \"_train_ids\", train_ids)\n",
      "        np.save(featurefile + \"_t_train\", t_train)\n",
      "        util.save_sparse_csr(featurefile + \"_mat\", X_train)\n",
      "        print \"generated and saved features\"\n",
      "    print\n",
      "        \n",
      "    return X_train, global_feat_dict, t_train, train_ids"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def toPandasDataFrame(Xarray, feat_dict, classes):\n",
      "    '''\n",
      "    arguments:\n",
      "        a sparse numpy matrix of features\n",
      "        a dictionary mapping column indexes to column names\n",
      "        a numpy array of class for element i\n",
      "    '''\n",
      "    data = pd.DataFrame(data=Xarray.toarray(), columns=feat_dict)\n",
      "    data['class'] = pd.Series(classes)\n",
      "    return data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "TYPES = 15 # this includes None\n",
      "\n",
      "def calculateNormalParams(data, category):\n",
      "    subset = data[[ data['class'] == category]]\n",
      "    subset.drop('class', axis=1, inplace=True)\n",
      "    \n",
      "    return (subset.cov(), subset.mean())\n",
      "\n",
      "def generative_model_predictions(ffs = None, featurefile=\"generative_features\", outputfile = \"generative_predictions.csv\", train_dir=\"train\", test_dir=\"test\"):\n",
      "    # do a quick load of feature data \n",
      "    X_train, global_feat_dict, t_train, train_ids = save_and_load(featurefile, train_dir, ffs)\n",
      "    \n",
      "    # now we need to train our model using generative baysian statistics\n",
      "    pdFrame = toPandasDataFrame(X_train, global_feat_dict, t_train)\n",
      "    \n",
      "    # subset by class and calculate the covariance matrices and the means\n",
      "    normal_params = [calculateNormalParams(pdFrame, i) for i in xrange(TYPES)] \n",
      "    \n",
      "    # calculate the normal distributions\n",
      "    normals = [stats.multivariate_normal(cov,mean) for cov, mean in normal_params]\n",
      "    \n",
      "    return X_train, global_feat_dict, t_train, train_ids"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x,f,r,i = generative_model_predictions([first_last_system_call_feats, tag_counts_feats, system_call_count_feats])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "generating feature set and saving to file: generative_features\n",
        "generated and saved features"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = toPandasDataFrame(x,f,r)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data[[data['class'] == 1, :'class']].head(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "SyntaxError",
       "evalue": "invalid syntax (<ipython-input-39-589a57bb7b7f>, line 1)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-39-589a57bb7b7f>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    data[[data['class'] == 1, :'class']].head(10)\u001b[0m\n\u001b[1;37m                              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y = pd.DataFrame(data=x.toarray())\n",
      "y.head(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>0</th>\n",
        "      <th>1</th>\n",
        "      <th>2</th>\n",
        "      <th>3</th>\n",
        "      <th>4</th>\n",
        "      <th>5</th>\n",
        "      <th>6</th>\n",
        "      <th>7</th>\n",
        "      <th>8</th>\n",
        "      <th>9</th>\n",
        "      <th>...</th>\n",
        "      <th>127</th>\n",
        "      <th>128</th>\n",
        "      <th>129</th>\n",
        "      <th>130</th>\n",
        "      <th>131</th>\n",
        "      <th>132</th>\n",
        "      <th>133</th>\n",
        "      <th>134</th>\n",
        "      <th>135</th>\n",
        "      <th>136</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td>  5</td>\n",
        "      <td>  0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 2</td>\n",
        "      <td>   2</td>\n",
        "      <td> 0</td>\n",
        "      <td>   1</td>\n",
        "      <td> 0</td>\n",
        "      <td>...</td>\n",
        "      <td> 0</td>\n",
        "      <td>  5</td>\n",
        "      <td>   0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td>  36</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td>  6</td>\n",
        "      <td>  0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 2</td>\n",
        "      <td>   2</td>\n",
        "      <td> 0</td>\n",
        "      <td>   1</td>\n",
        "      <td> 0</td>\n",
        "      <td>...</td>\n",
        "      <td> 0</td>\n",
        "      <td>  6</td>\n",
        "      <td>   0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td>  36</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 49</td>\n",
        "      <td> 23</td>\n",
        "      <td> 0</td>\n",
        "      <td> 4</td>\n",
        "      <td> 470</td>\n",
        "      <td> 0</td>\n",
        "      <td> 338</td>\n",
        "      <td> 5</td>\n",
        "      <td>...</td>\n",
        "      <td> 0</td>\n",
        "      <td> 49</td>\n",
        "      <td> 637</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 307</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 3</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td>  1</td>\n",
        "      <td>  0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td>   0</td>\n",
        "      <td> 0</td>\n",
        "      <td>   0</td>\n",
        "      <td> 0</td>\n",
        "      <td>...</td>\n",
        "      <td> 0</td>\n",
        "      <td>  1</td>\n",
        "      <td>   0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td>  22</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td>  5</td>\n",
        "      <td>  0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 2</td>\n",
        "      <td>   2</td>\n",
        "      <td> 0</td>\n",
        "      <td>   1</td>\n",
        "      <td> 0</td>\n",
        "      <td>...</td>\n",
        "      <td> 0</td>\n",
        "      <td>  5</td>\n",
        "      <td>   0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td>  36</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5</th>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td>  7</td>\n",
        "      <td>  0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 3</td>\n",
        "      <td>  21</td>\n",
        "      <td> 0</td>\n",
        "      <td>   4</td>\n",
        "      <td> 0</td>\n",
        "      <td>...</td>\n",
        "      <td> 0</td>\n",
        "      <td>  7</td>\n",
        "      <td>   0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td>  48</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6</th>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td>  5</td>\n",
        "      <td>  0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 2</td>\n",
        "      <td>   2</td>\n",
        "      <td> 0</td>\n",
        "      <td>   1</td>\n",
        "      <td> 0</td>\n",
        "      <td>...</td>\n",
        "      <td> 0</td>\n",
        "      <td>  5</td>\n",
        "      <td>   0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td>  36</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7</th>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td>  2</td>\n",
        "      <td>  0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 2</td>\n",
        "      <td>   0</td>\n",
        "      <td> 0</td>\n",
        "      <td>   0</td>\n",
        "      <td> 0</td>\n",
        "      <td>...</td>\n",
        "      <td> 0</td>\n",
        "      <td>  2</td>\n",
        "      <td>   0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td>  10</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8</th>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td>  8</td>\n",
        "      <td>  0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 2</td>\n",
        "      <td>  34</td>\n",
        "      <td> 0</td>\n",
        "      <td>   3</td>\n",
        "      <td> 0</td>\n",
        "      <td>...</td>\n",
        "      <td> 0</td>\n",
        "      <td>  8</td>\n",
        "      <td>   0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 104</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9</th>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td>  1</td>\n",
        "      <td>  0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td>   0</td>\n",
        "      <td> 0</td>\n",
        "      <td>   0</td>\n",
        "      <td> 0</td>\n",
        "      <td>...</td>\n",
        "      <td> 0</td>\n",
        "      <td>  1</td>\n",
        "      <td>   0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td>   0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>10 rows \u00d7 137 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 23,
       "text": [
        "   0    1    2    3    4    5    6    7    8    9   ...   127  128  129  130  \\\n",
        "0    0    0    5    0    0    2    2    0    1    0 ...     0    5    0    0   \n",
        "1    0    0    6    0    0    2    2    0    1    0 ...     0    6    0    0   \n",
        "2    0    0   49   23    0    4  470    0  338    5 ...     0   49  637    0   \n",
        "3    0    0    1    0    0    1    0    0    0    0 ...     0    1    0    0   \n",
        "4    0    0    5    0    0    2    2    0    1    0 ...     0    5    0    0   \n",
        "5    0    0    7    0    0    3   21    0    4    0 ...     0    7    0    0   \n",
        "6    0    0    5    0    0    2    2    0    1    0 ...     0    5    0    0   \n",
        "7    0    0    2    0    0    2    0    0    0    0 ...     0    2    0    0   \n",
        "8    0    0    8    0    0    2   34    0    3    0 ...     0    8    0    0   \n",
        "9    0    0    1    0    0    1    0    0    0    0 ...     0    1    0    0   \n",
        "\n",
        "   131  132  133  134  135  136  \n",
        "0    0    0   36    0    0    0  \n",
        "1    0    0   36    0    0    0  \n",
        "2    0    0  307    0    0    3  \n",
        "3    0    0   22    0    0    0  \n",
        "4    0    0   36    0    0    0  \n",
        "5    0    0   48    0    0    0  \n",
        "6    0    0   36    0    0    0  \n",
        "7    0    0   10    0    0    0  \n",
        "8    0    0  104    0    0    0  \n",
        "9    0    0    0    0    0    0  \n",
        "\n",
        "[10 rows x 137 columns]"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}